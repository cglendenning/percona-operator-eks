#!/bin/bash
#
# PXC Point-in-Time Restore CLI
# Restores backups from a source namespace to an existing PXC cluster in a target namespace.
# Uses kubectl directly - no API server required.
#
# Prerequisites:
#   - Source namespace with PXC backups (source cluster may be unhealthy)
#   - Target namespace with a healthy PXC cluster ready to receive the restore
#

set -euo pipefail

# Configuration
KUBECONFIG="${KUBECONFIG:-}"
VERBOSE=false
DRY_RUN=false
SOURCE_NAMESPACE=""
TARGET_NAMESPACE=""
TARGET_CLUSTER=""
BACKUP_NAME=""
RESTORE_TIME=""
PITR_AVAILABLE=false

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# Logging functions
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[OK]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1" >&2; }
log_dry() { echo -e "${CYAN}[DRY-RUN]${NC} $1"; }
log_header() {
    echo ""
    echo -e "${CYAN}=====================================================${NC}"
    echo -e "${CYAN}  $1${NC}"
    echo -e "${CYAN}=====================================================${NC}"
    echo ""
}

# kubectl wrapper
kctl() {
    if [ -n "$KUBECONFIG" ]; then
        kubectl --kubeconfig="$KUBECONFIG" "$@"
    else
        kubectl "$@"
    fi
}

# Usage
usage() {
    cat << EOF
PXC Point-in-Time Restore CLI

Restores backups from a source namespace to an existing PXC cluster in a target namespace.

PREREQUISITES:
    - Source namespace with PXC backups (source cluster may be unhealthy/down)
    - Target namespace with a HEALTHY PXC cluster ready to receive the restore

USAGE:
    $0 -n SOURCE_NAMESPACE -t TARGET_NAMESPACE [OPTIONS]

REQUIRED:
    -n, --namespace NAMESPACE   Source namespace containing the backups to restore from
    -t, --target NAMESPACE      Target namespace with healthy PXC cluster to restore to

OPTIONS:
    -c, --cluster NAME          Target cluster name (auto-detected if only one cluster exists)
    -b, --backup NAME           Backup name (will prompt if not provided)
    -r, --restore-time TIME     Restore time in "YYYY-MM-DD HH:MM:SS" UTC format
    --dry-run                   Show what would be done without making changes
    --kubeconfig PATH           Path to kubeconfig file
    -v, --verbose               Enable verbose output
    -h, --help                  Show this help message

EXAMPLES:
    # Interactive restore
    $0 -n percona-source -t percona-dr

    # Dry run to verify prerequisites
    $0 -n percona-source -t percona-dr --dry-run

    # Non-interactive with all options
    $0 -n percona-source -t percona-dr -b daily-backup-20250115 -r "2025-01-15 14:30:00"

    # Specify target cluster explicitly
    $0 -n percona-source -t percona-dr -c db

TIME FORMAT:
    YYYY-MM-DD HH:MM:SS (UTC)
    Example: 2025-01-15 14:30:00

WORKFLOW:
    1. Verifies backups exist in source namespace
    2. Verifies target cluster exists and is healthy
    3. Lists available backups and prompts for selection
    4. Shows earliest and latest restorable times
    5. Prompts for restore time
    6. Copies backup resource to target namespace
    7. Creates restore resource on target cluster
    8. Waits for restore completion
    9. Displays database summary

NOTE: The source namespace is NEVER modified. The restore is applied to the target cluster.
EOF
    exit 0
}

# Check prerequisites
check_prerequisites() {
    local errors=0
    local warnings=0

    log_header "Checking Prerequisites"

    # Check kubectl
    if command -v kubectl &> /dev/null; then
        local kversion
        kversion=$(kubectl version --client -o json 2>/dev/null | jq -r '.clientVersion.gitVersion' 2>/dev/null || echo "unknown")
        log_success "kubectl installed: $kversion"
    else
        log_error "kubectl is not installed or not in PATH"
        ((errors++))
    fi

    # Check jq
    if command -v jq &> /dev/null; then
        log_success "jq installed: $(jq --version)"
    else
        log_error "jq is not installed (required for JSON parsing)"
        ((errors++))
    fi

    # Check base64
    if command -v base64 &> /dev/null; then
        log_success "base64 installed"
    else
        log_error "base64 is not installed (required for secret decoding)"
        ((errors++))
    fi

    # Check cluster connectivity
    if kctl cluster-info &>/dev/null; then
        local context
        context=$(kctl config current-context 2>/dev/null || echo "unknown")
        log_success "Kubernetes cluster accessible (context: $context)"
    else
        log_error "Cannot connect to Kubernetes cluster"
        ((errors++))
        echo ""
        log_error "$errors prerequisite check(s) failed"
        return 1
    fi

    # Check PXC operator CRDs are installed
    if kctl get crd perconaxtradbclusters.pxc.percona.com &>/dev/null; then
        log_success "PXC operator CRDs installed"
    else
        log_error "PXC operator CRDs not installed"
        ((errors++))
    fi

    echo ""
    log_info "--- Source Namespace Checks ---"

    # Check source namespace exists
    if kctl get namespace "$SOURCE_NAMESPACE" &>/dev/null; then
        log_success "Source namespace exists: $SOURCE_NAMESPACE"
    else
        log_error "Source namespace does not exist: $SOURCE_NAMESPACE"
        ((errors++))
    fi

    # Check for backups in source namespace (this is the key requirement)
    local backup_count succeeded_count
    backup_count=$(kctl get perconaxtradbclusterbackup -n "$SOURCE_NAMESPACE" -o json 2>/dev/null | jq '.items | length' 2>/dev/null || echo "0")
    succeeded_count=$(kctl get perconaxtradbclusterbackup -n "$SOURCE_NAMESPACE" -o json 2>/dev/null | jq '[.items[] | select(.status.state == "Succeeded" or .status.state == "Ready")] | length' 2>/dev/null || echo "0")
    
    if [ "$backup_count" -gt 0 ]; then
        log_success "Found $backup_count backup(s) in source namespace ($succeeded_count succeeded)"
        if [ "$succeeded_count" -eq 0 ]; then
            log_error "No backups in Succeeded state - cannot restore"
            ((errors++))
        fi
    else
        log_error "No backups found in source namespace: $SOURCE_NAMESPACE"
        ((errors++))
    fi

    # Check source cluster exists (for reference, may not be healthy)
    local source_cluster_name=""
    source_cluster_name=$(kctl get perconaxtradbcluster -n "$SOURCE_NAMESPACE" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
    if [ -n "$source_cluster_name" ]; then
        local source_state
        source_state=$(kctl get perconaxtradbcluster "$source_cluster_name" -n "$SOURCE_NAMESPACE" -o jsonpath='{.status.state}' 2>/dev/null || echo "unknown")
        log_info "Source cluster: $source_cluster_name (state: $source_state)"
        if [ "$source_state" != "ready" ]; then
            log_info "  Source cluster is not healthy - this is expected for DR scenarios"
        fi
    else
        log_info "No PXC cluster found in source namespace (backups may be orphaned)"
    fi

    echo ""
    log_info "--- Target Namespace Checks ---"

    # Check target namespace exists
    if kctl get namespace "$TARGET_NAMESPACE" &>/dev/null; then
        log_success "Target namespace exists: $TARGET_NAMESPACE"
    else
        log_error "Target namespace does not exist: $TARGET_NAMESPACE"
        ((errors++))
    fi

    # Check for healthy PXC cluster in target namespace
    local target_cluster_count
    target_cluster_count=$(kctl get perconaxtradbcluster -n "$TARGET_NAMESPACE" -o json 2>/dev/null | jq '.items | length' 2>/dev/null || echo "0")
    
    if [ "$target_cluster_count" -eq 0 ]; then
        log_error "No PXC cluster found in target namespace: $TARGET_NAMESPACE"
        log_error "A healthy PXC cluster must exist in the target namespace"
        ((errors++))
    elif [ "$target_cluster_count" -eq 1 ]; then
        TARGET_CLUSTER=$(kctl get perconaxtradbcluster -n "$TARGET_NAMESPACE" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
        log_success "Found target cluster: $TARGET_CLUSTER"
        
        # Check target cluster is healthy
        local target_state
        target_state=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o jsonpath='{.status.state}' 2>/dev/null || echo "unknown")
        
        if [ "$target_state" = "ready" ]; then
            log_success "Target cluster is healthy (state: ready)"
        else
            log_error "Target cluster is NOT healthy (state: $target_state)"
            log_error "Target cluster must be in 'ready' state to receive restore"
            ((errors++))
        fi
        
        # Show target cluster details
        local pxc_ready pxc_size
        pxc_ready=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o jsonpath='{.status.pxc.ready}' 2>/dev/null || echo "0")
        pxc_size=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o jsonpath='{.status.pxc.size}' 2>/dev/null || echo "?")
        log_info "  PXC nodes: $pxc_ready/$pxc_size ready"
    else
        # Multiple clusters - need user to specify
        if [ -z "$TARGET_CLUSTER" ]; then
            log_warn "Multiple PXC clusters found in target namespace"
            log_warn "Use -c or --cluster to specify which cluster to restore to:"
            kctl get perconaxtradbcluster -n "$TARGET_NAMESPACE" -o jsonpath='{range .items[*]}  - {.metadata.name} (state: {.status.state}){"\n"}{end}' 2>/dev/null
            ((errors++))
        else
            # Verify specified cluster exists
            if kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" &>/dev/null; then
                local target_state
                target_state=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o jsonpath='{.status.state}' 2>/dev/null || echo "unknown")
                if [ "$target_state" = "ready" ]; then
                    log_success "Target cluster is healthy: $TARGET_CLUSTER (state: ready)"
                else
                    log_error "Target cluster is NOT healthy: $TARGET_CLUSTER (state: $target_state)"
                    ((errors++))
                fi
            else
                log_error "Specified cluster not found: $TARGET_CLUSTER"
                ((errors++))
            fi
        fi
    fi

    echo ""
    if [ $errors -gt 0 ]; then
        log_error "$errors prerequisite check(s) failed"
        if [ $warnings -gt 0 ]; then
            log_warn "$warnings warning(s)"
        fi
        return 1
    else
        log_success "All prerequisite checks passed"
        if [ $warnings -gt 0 ]; then
            log_warn "$warnings warning(s) - review above for details"
        fi
        return 0
    fi
}

# Get cluster name from namespace
get_cluster_name() {
    local ns="$1"
    kctl get perconaxtradbcluster -n "$ns" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo ""
}

# List backups and return JSON
get_backups() {
    local ns="$1"
    kctl get perconaxtradbclusterbackup -n "$ns" -o json 2>/dev/null || echo '{"items":[]}'
}

# Display backups and let user select
display_and_select_backup() {
    local ns="$1"
    local backups_json
    backups_json=$(get_backups "$ns")

    local backup_count
    backup_count=$(echo "$backups_json" | jq '.items | length')

    if [ "$backup_count" -eq 0 ]; then
        log_error "No backups found in namespace: $ns"
        exit 1
    fi

    log_header "Available Backups"

    # Build arrays for selection
    local -a backup_names=()
    local -a backup_states=()
    local -a backup_completed=()
    local -a backup_latest=()
    local -a backup_pitr=()
    local -a backup_storage=()

    while IFS= read -r item; do
        local name state completed latest pitr storage
        name=$(echo "$item" | jq -r '.metadata.name')
        state=$(echo "$item" | jq -r '.status.state // "Unknown"')
        completed=$(echo "$item" | jq -r '.status.completed // ""')
        latest=$(echo "$item" | jq -r '.status.latestRestorableTime // ""')
        storage=$(echo "$item" | jq -r '.spec.storageName // ""')
        
        # Check PITRReady condition
        pitr=$(echo "$item" | jq -r '.status.conditions[]? | select(.type=="PITRReady") | .status' 2>/dev/null || echo "")
        if [ "$pitr" = "True" ]; then
            pitr="Yes"
        else
            pitr="No"
        fi

        # Only include succeeded backups
        if [ "$state" = "Succeeded" ] || [ "$state" = "Ready" ]; then
            backup_names+=("$name")
            backup_states+=("$state")
            backup_completed+=("$completed")
            backup_latest+=("$latest")
            backup_pitr+=("$pitr")
            backup_storage+=("$storage")
        fi
    done < <(echo "$backups_json" | jq -c '.items[]')

    local valid_count=${#backup_names[@]}
    if [ "$valid_count" -eq 0 ]; then
        log_error "No completed backups found in namespace: $ns"
        exit 1
    fi

    # Display table with backup completed time and latest restorable time
    printf "%-4s %-35s %-10s %-6s %-20s %-20s\n" "#" "BACKUP NAME" "STATE" "PITR" "COMPLETED (UTC)" "LATEST RESTORABLE"
    printf "%s\n" "--------------------------------------------------------------------------------------------------------------"

    for i in "${!backup_names[@]}"; do
        local idx=$((i + 1))
        local completed_display="${backup_completed[$i]}"
        local latest_display="${backup_latest[$i]}"
        
        if [ -n "$completed_display" ]; then
            completed_display=$(echo "$completed_display" | sed 's/T/ /g' | sed 's/Z//g' | cut -c1-19)
        else
            completed_display="N/A"
        fi
        
        if [ -n "$latest_display" ]; then
            latest_display=$(echo "$latest_display" | sed 's/T/ /g' | sed 's/Z//g' | cut -c1-19)
        else
            latest_display="N/A"
        fi
        printf "%-4s %-35s %-10s %-6s %-20s %-20s\n" "[$idx]" "${backup_names[$i]}" "${backup_states[$i]}" "${backup_pitr[$i]}" "$completed_display" "$latest_display"
    done
    echo ""

    # Select backup first
    local selected_idx
    if [ -n "$BACKUP_NAME" ]; then
        # Find index of specified backup
        for i in "${!backup_names[@]}"; do
            if [ "${backup_names[$i]}" = "$BACKUP_NAME" ]; then
                selected_idx=$i
                break
            fi
        done
        if [ -z "$selected_idx" ]; then
            log_error "Specified backup not found: $BACKUP_NAME"
            exit 1
        fi
        log_info "Using specified backup: $BACKUP_NAME"
    else
        echo -n "Select backup number [1]: "
        read -r backup_num
        backup_num=${backup_num:-1}

        if ! [[ "$backup_num" =~ ^[0-9]+$ ]] || [ "$backup_num" -lt 1 ] || [ "$backup_num" -gt "$valid_count" ]; then
            log_error "Invalid backup selection"
            exit 1
        fi
        selected_idx=$((backup_num - 1))
    fi

    BACKUP_NAME="${backup_names[$selected_idx]}"
    log_success "Selected backup: ${BACKUP_NAME}"

    # Export for later use
    BACKUP_COMPLETED="${backup_completed[$selected_idx]}"
    BACKUP_LATEST="${backup_latest[$selected_idx]}"
    BACKUP_STORAGE="${backup_storage[$selected_idx]}"

    # Now show the restorable time window for this specific backup
    log_header "Restorable Time Window for Selected Backup"

    local earliest_formatted=""
    local latest_formatted=""

    if [ -n "$BACKUP_COMPLETED" ]; then
        earliest_formatted=$(echo "$BACKUP_COMPLETED" | sed 's/T/ /g' | sed 's/Z//g' | cut -c1-19)
    fi
    if [ -n "$BACKUP_LATEST" ]; then
        latest_formatted=$(echo "$BACKUP_LATEST" | sed 's/T/ /g' | sed 's/Z//g' | cut -c1-19)
    fi

    # Track if PITR is available
    PITR_AVAILABLE=false
    
    if [ -n "$earliest_formatted" ] && [ -n "$latest_formatted" ] && [ "$earliest_formatted" != "$latest_formatted" ]; then
        PITR_AVAILABLE=true
        echo -e "  ${CYAN}Earliest (backup completed):${NC}  ${earliest_formatted} UTC"
        echo -e "  ${CYAN}Latest (binlogs available):${NC}   ${latest_formatted} UTC"
        echo ""
        echo "  You can restore to any point in time between these two timestamps."
        echo "  The earliest time is when the backup completed."
        echo "  The latest time is based on available binlogs (latestRestorableTime)."
    elif [ -n "$earliest_formatted" ]; then
        echo -e "  ${CYAN}Backup completed:${NC} ${earliest_formatted} UTC"
        echo ""
        if [ -z "$BACKUP_LATEST" ]; then
            log_warn "No latestRestorableTime available - this backup has no PITR binlogs."
            log_info "This is normal for a freshly taken backup."
            echo "  Will restore to the backup state (non-PITR restore)."
        else
            log_info "Backup completion time equals latest restorable time."
            echo "  Will restore to the backup state."
        fi
        latest_formatted="$earliest_formatted"
    else
        log_error "Cannot determine restorable time window for this backup."
        exit 1
    fi

    echo ""
    echo -e "  ${BOLD}Required format: YYYY-MM-DD HH:MM:SS${NC}"
    echo ""

    # Get restore time
    if [ -z "$RESTORE_TIME" ]; then
        local default_time="${latest_formatted:-}"

        echo -n "Enter restore time [${default_time}]: "
        read -r input_time
        RESTORE_TIME="${input_time:-$default_time}"
    fi

    # Validate time format
    if [ -n "$RESTORE_TIME" ]; then
        if ! [[ "$RESTORE_TIME" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}\ [0-9]{2}:[0-9]{2}:[0-9]{2}$ ]]; then
            log_error "Invalid time format. Use: YYYY-MM-DD HH:MM:SS"
            exit 1
        fi
        
        # Validate time is within the window
        if [ -n "$earliest_formatted" ] && [ -n "$latest_formatted" ]; then
            if [[ "$RESTORE_TIME" < "$earliest_formatted" ]]; then
                log_error "Restore time is before the backup completion time ($earliest_formatted)"
                exit 1
            fi
            if [[ "$RESTORE_TIME" > "$latest_formatted" ]]; then
                log_error "Restore time is after the latest restorable time ($latest_formatted)"
                log_error "Binlogs are not available beyond this point."
                exit 1
            fi
        fi
        
        log_success "Restore time: ${RESTORE_TIME} UTC"
    else
        log_error "Restore time is required"
        exit 1
    fi
}



# Copy backup resource from source to target namespace
copy_backup_resource() {
    local backup_name="$1"
    local source_ns="$2"
    local target_ns="$3"

    log_info "Copying backup resource to target namespace..."

    if ! kctl get perconaxtradbclusterbackup "$backup_name" -n "$source_ns" &>/dev/null; then
        log_error "Backup resource not found: $backup_name in $source_ns"
        return 1
    fi

    if [ "$DRY_RUN" = true ]; then
        log_dry "Would copy backup resource: $backup_name from $source_ns to $target_ns"
        return 0
    fi

    # Get full backup including status
    local backup_json
    backup_json=$(kctl get perconaxtradbclusterbackup "$backup_name" -n "$source_ns" -o json)

    # Extract status before modifying (status contains critical backup destination info)
    local backup_status
    backup_status=$(echo "$backup_json" | jq '.status')

    # Modify metadata for target namespace
    backup_json=$(echo "$backup_json" | jq --arg ns "$target_ns" '
        .metadata.namespace = $ns |
        del(.metadata.resourceVersion) |
        del(.metadata.uid) |
        del(.metadata.creationTimestamp) |
        del(.metadata.generation) |
        del(.metadata.managedFields) |
        del(.metadata.ownerReferences) |
        del(.metadata.finalizers) |
        del(.status)
    ')

    # Apply the backup resource (creates without status)
    if ! echo "$backup_json" | kctl apply -f - &>/dev/null; then
        log_warn "Failed to create backup resource (may already exist)"
    fi

    # Now patch the status subresource - this is critical for restore to find the backup data
    if [ "$backup_status" != "null" ] && [ -n "$backup_status" ]; then
        local status_patch
        status_patch=$(echo "$backup_status" | jq '{status: .}')
        
        if kctl patch perconaxtradbclusterbackup "$backup_name" -n "$target_ns" \
            --type=merge --subresource=status -p "$status_patch" &>/dev/null; then
            log_success "Copied backup resource with status: $backup_name"
        else
            # Fallback: try strategic merge patch
            if kctl patch perconaxtradbclusterbackup "$backup_name" -n "$target_ns" \
                --type=strategic --subresource=status -p "$status_patch" &>/dev/null; then
                log_success "Copied backup resource with status: $backup_name"
            else
                log_warn "Could not patch backup status - restore may fail"
                log_warn "Backup destination from source: $(echo "$backup_status" | jq -r '.destination // "unknown"')"
            fi
        fi
    else
        log_success "Copied backup resource: $backup_name"
    fi

    return 0
}


# Create restore resource
create_restore() {
    local target_ns="$1"
    local target_cluster="$2"
    local backup_name="$3"
    local restore_time="$4"
    local storage_name="$5"
    local source_ns="$6"

    local restore_name="restore-${target_cluster}-$(date +%s)"

    log_header "Creating Restore Resource"

    # The restore needs the backup resource in the target namespace
    copy_backup_resource "$backup_name" "$source_ns" "$target_ns"

    local restore_yaml
    
    if [ "$PITR_AVAILABLE" = true ]; then
        # PITR restore - restore to specific point in time
        log_info "Creating PITR restore to: $restore_time"
        restore_yaml=$(cat <<EOF
apiVersion: pxc.percona.com/v1
kind: PerconaXtraDBClusterRestore
metadata:
  name: ${restore_name}
  namespace: ${target_ns}
spec:
  pxcCluster: ${target_cluster}
  backupName: ${backup_name}
  pitr:
    type: date
    date: "${restore_time}"
    backupSource:
      storageName: ${storage_name}
EOF
)
    else
        # Non-PITR restore - restore from backup only (no binlogs)
        log_info "Creating non-PITR restore from backup: $backup_name"
        restore_yaml=$(cat <<EOF
apiVersion: pxc.percona.com/v1
kind: PerconaXtraDBClusterRestore
metadata:
  name: ${restore_name}
  namespace: ${target_ns}
spec:
  pxcCluster: ${target_cluster}
  backupName: ${backup_name}
EOF
)
    fi

    if [ "$DRY_RUN" = true ]; then
        log_dry "Would create restore resource:"
        echo ""
        echo "$restore_yaml"
        echo ""
        RESTORE_NAME="$restore_name"
        return 0
    fi

    log_info "Creating restore: $restore_name"

    if echo "$restore_yaml" | kctl apply -f -; then
        log_success "Restore resource created"
        RESTORE_NAME="$restore_name"
        return 0
    else
        log_error "Failed to create restore resource"
        return 1
    fi
}

# Wait for restore to complete
wait_for_restore() {
    local target_ns="$1"
    local restore_name="$2"
    local target_cluster="$3"

    log_header "Waiting for Restore"
    log_info "This may take several minutes..."
    log_info "Restore resource: $restore_name"
    echo ""

    local max_attempts=120  # 10 minutes with 5 second intervals
    local attempt=0
    local last_state=""
    local last_cluster_state=""
    local start_time
    start_time=$(date +%s)

    while [ $attempt -lt $max_attempts ]; do
        ((attempt++))
        local elapsed=$(($(date +%s) - start_time))
        local elapsed_min=$((elapsed / 60))
        local elapsed_sec=$((elapsed % 60))

        # Get restore status
        local restore_state restore_completed restore_lastscheduled
        restore_state=$(kctl get perconaxtradbclusterrestore "$restore_name" -n "$target_ns" -o jsonpath='{.status.state}' 2>/dev/null || echo "")
        restore_completed=$(kctl get perconaxtradbclusterrestore "$restore_name" -n "$target_ns" -o jsonpath='{.status.completed}' 2>/dev/null || echo "")

        # Handle empty restore state (resource just created)
        if [ -z "$restore_state" ]; then
            restore_state="Initializing"
        fi

        # Get cluster status
        local cluster_state pxc_ready pxc_size
        cluster_state=$(kctl get perconaxtradbcluster "$target_cluster" -n "$target_ns" -o jsonpath='{.status.state}' 2>/dev/null || echo "")
        pxc_ready=$(kctl get perconaxtradbcluster "$target_cluster" -n "$target_ns" -o jsonpath='{.status.pxc.ready}' 2>/dev/null || echo "")
        pxc_size=$(kctl get perconaxtradbcluster "$target_cluster" -n "$target_ns" -o jsonpath='{.status.pxc.size}' 2>/dev/null || echo "")

        # Handle empty cluster state
        if [ -z "$cluster_state" ]; then
            cluster_state="waiting"
        fi

        # Get actual pod status for more detail
        local pod_status=""
        local running_pods=0
        local total_pods=0
        local pending_pods=0
        local restoring_pods=0
        
        # Count pods by status
        while IFS= read -r line; do
            if [ -n "$line" ]; then
                ((total_pods++))
                case "$line" in
                    *Running*) ((running_pods++)) ;;
                    *Pending*|*ContainerCreating*) ((pending_pods++)) ;;
                    *Init*) ((restoring_pods++)) ;;
                esac
            fi
        done < <(kctl get pods -n "$target_ns" -l "app.kubernetes.io/instance=$target_cluster" --no-headers 2>/dev/null || echo "")

        # Build node status string
        local node_info=""
        if [ -n "$pxc_ready" ] && [ -n "$pxc_size" ]; then
            node_info="$pxc_ready/$pxc_size ready"
        elif [ "$total_pods" -gt 0 ]; then
            node_info="$running_pods running, $pending_pods pending"
            if [ "$restoring_pods" -gt 0 ]; then
                node_info="$node_info, $restoring_pods restoring"
            fi
        else
            node_info="waiting for pods"
        fi

        # Print state change as a new line for visibility
        if [ "$restore_state" != "$last_state" ] || [ "$cluster_state" != "$last_cluster_state" ]; then
            if [ -n "$last_state" ]; then
                echo ""  # Move to new line after previous status
            fi
            printf "  [%02d:%02d] Restore: %-12s | Cluster: %-12s | Pods: %s\n" \
                "$elapsed_min" "$elapsed_sec" "$restore_state" "$cluster_state" "$node_info"
            last_state="$restore_state"
            last_cluster_state="$cluster_state"
        else
            # Update on same line for minor updates
            printf "\r  [%02d:%02d] Restore: %-12s | Cluster: %-12s | Pods: %s          " \
                "$elapsed_min" "$elapsed_sec" "$restore_state" "$cluster_state" "$node_info"
        fi

        # Check completion
        if [ "$restore_state" = "Succeeded" ] || [ "$restore_state" = "Ready" ]; then
            if [ "$cluster_state" = "ready" ]; then
                echo ""
                log_success "Restore completed successfully in ${elapsed_min}m ${elapsed_sec}s"
                if [ -n "$restore_completed" ]; then
                    log_info "Restore finished at: $restore_completed"
                fi
                return 0
            fi
        elif [ "$restore_state" = "Failed" ] || [ "$restore_state" = "Error" ]; then
            echo ""
            local message
            message=$(kctl get perconaxtradbclusterrestore "$restore_name" -n "$target_ns" -o jsonpath='{.status.comments}' 2>/dev/null || echo "Unknown error")
            log_error "Restore failed: $message"
            echo ""
            log_info "Debugging info:"
            kctl describe perconaxtradbclusterrestore "$restore_name" -n "$target_ns" 2>/dev/null | tail -20
            return 1
        fi

        sleep 5
    done

    echo ""
    log_error "Restore timed out after 10 minutes"
    echo ""
    log_info "Current restore status:"
    kctl get perconaxtradbclusterrestore "$restore_name" -n "$target_ns" -o wide 2>/dev/null || echo "  Could not get restore status"
    echo ""
    log_info "Current cluster status:"
    kctl get perconaxtradbcluster "$target_cluster" -n "$target_ns" -o wide 2>/dev/null || echo "  Could not get cluster status"
    echo ""
    log_info "Current pods:"
    kctl get pods -n "$target_ns" -l "app.kubernetes.io/instance=$target_cluster" 2>/dev/null || echo "  Could not get pods"
    return 1
}

# Get database summary
get_database_summary() {
    local target_ns="$1"
    local target_cluster="$2"

    log_header "Database Summary"

    # Get root password - first check what secretsName the cluster uses
    local secrets_name
    secrets_name=$(kctl get perconaxtradbcluster "$target_cluster" -n "$target_ns" -o jsonpath='{.spec.secretsName}' 2>/dev/null || echo "")
    if [ -z "$secrets_name" ]; then
        # Fallback to convention
        secrets_name="${target_cluster}-secrets"
    fi
    
    local root_pwd_b64
    root_pwd_b64=$(kctl get secret "$secrets_name" -n "$target_ns" -o jsonpath='{.data.root}' 2>/dev/null || echo "")

    if [ -z "$root_pwd_b64" ]; then
        log_warn "Could not get root password from secret"
        echo ""
        echo "  Connect manually to view databases:"
        echo -e "  ${CYAN}kubectl exec -it ${target_cluster}-pxc-0 -n ${target_ns} -c pxc -- mysql -uroot -p${NC}"
        return
    fi

    local root_pwd
    root_pwd=$(echo "$root_pwd_b64" | base64 -d 2>/dev/null || echo "")

    if [ -z "$root_pwd" ]; then
        log_warn "Could not decode root password"
        return
    fi

    # Get databases and table counts
    local pod_name="${target_cluster}-pxc-0"
    
    log_info "Querying database information..."
    
    # Use a simple, reliable query with a delimiter we can parse
    # Output format: db_name|table_count
    local db_summary_query="SELECT CONCAT(s.SCHEMA_NAME, '|', IFNULL(t.table_count, 0)) FROM information_schema.SCHEMATA s LEFT JOIN (SELECT TABLE_SCHEMA, COUNT(*) as table_count FROM information_schema.TABLES GROUP BY TABLE_SCHEMA) t ON s.SCHEMA_NAME = t.TABLE_SCHEMA WHERE s.SCHEMA_NAME NOT IN ('information_schema', 'mysql', 'performance_schema', 'sys') ORDER BY s.SCHEMA_NAME"

    local db_results
    db_results=$(kctl exec -n "$target_ns" "$pod_name" -c pxc -- mysql -uroot -p"$root_pwd" -N -e "$db_summary_query" 2>/dev/null)
    local query_exit=$?

    if [ $query_exit -ne 0 ] || [ -z "$db_results" ]; then
        # Try a simpler fallback - just list databases
        log_info "Trying alternative query..."
        local db_list
        db_list=$(kctl exec -n "$target_ns" "$pod_name" -c pxc -- mysql -uroot -p"$root_pwd" -N -e "SHOW DATABASES" 2>/dev/null)
        
        if [ -z "$db_list" ]; then
            log_warn "Could not query databases"
            echo ""
            echo "  Connect to the restored cluster:"
            echo -e "  ${CYAN}kubectl exec -it ${target_cluster}-pxc-0 -n ${target_ns} -c pxc -- mysql -uroot -p${NC}"
            return
        fi
        
        # Filter out system databases and show what we have
        echo ""
        printf "  %-30s\n" "USER DATABASES"
        printf "  %s\n" "----------------------------------------"
        
        local db_count=0
        while IFS= read -r db; do
            db=$(echo "$db" | tr -d '\r\n' | xargs)
            case "$db" in
                information_schema|mysql|performance_schema|sys|"") ;;
                *)
                    printf "  %s\n" "$db"
                    ((db_count++))
                    ;;
            esac
        done <<< "$db_list"
        
        printf "  %s\n" "----------------------------------------"
        if [ "$db_count" -eq 0 ]; then
            echo "  No user databases found (only system databases exist)."
        else
            echo "  Total: $db_count database(s)"
        fi
    else
        # Parse the results (format: db_name|table_count)
        echo ""
        printf "  %-30s %s\n" "DATABASE" "TABLES"
        printf "  %s\n" "----------------------------------------"

        local total_tables=0
        local total_dbs=0
        
        # Use here-string to avoid subshell issues with pipe
        while IFS= read -r line; do
            # Clean up the line
            line=$(echo "$line" | tr -d '\r\n')
            
            if [ -n "$line" ]; then
                # Split on pipe delimiter
                local db_name="${line%%|*}"
                local table_count="${line##*|}"
                
                # Clean up values
                db_name=$(echo "$db_name" | xargs)
                table_count=$(echo "$table_count" | xargs)
                
                if [ -n "$db_name" ]; then
                    # Ensure table_count is numeric
                    if ! [[ "$table_count" =~ ^[0-9]+$ ]]; then
                        table_count="0"
                    fi
                    printf "  %-30s %s\n" "$db_name" "$table_count"
                    ((total_dbs++))
                    total_tables=$((total_tables + table_count))
                fi
            fi
        done <<< "$db_results"
        
        printf "  %s\n" "----------------------------------------"
        printf "  %-30s %s\n" "TOTAL ($total_dbs databases)" "$total_tables tables"
    fi

    echo ""
    echo "  Connect to the restored cluster:"
    echo -e "  ${CYAN}kubectl exec -it ${target_cluster}-pxc-0 -n ${target_ns} -c pxc -- mysql -uroot -p${NC}"
}

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -n|--namespace)
            SOURCE_NAMESPACE="$2"
            shift 2
            ;;
        -t|--target)
            TARGET_NAMESPACE="$2"
            shift 2
            ;;
        -c|--cluster)
            TARGET_CLUSTER="$2"
            shift 2
            ;;
        -b|--backup)
            BACKUP_NAME="$2"
            shift 2
            ;;
        -r|--restore-time)
            RESTORE_TIME="$2"
            shift 2
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --kubeconfig)
            KUBECONFIG="$2"
            shift 2
            ;;
        -v|--verbose)
            VERBOSE=true
            shift
            ;;
        -h|--help)
            usage
            ;;
        *)
            log_error "Unknown option: $1"
            echo ""
            usage
            ;;
    esac
done

# Validate required arguments
if [ -z "$SOURCE_NAMESPACE" ]; then
    log_error "Source namespace is required. Use -n or --namespace."
    echo ""
    usage
fi

if [ -z "$TARGET_NAMESPACE" ]; then
    log_error "Target namespace is required. Use -t or --target."
    echo ""
    usage
fi

# Main execution
log_header "PXC Point-in-Time Restore"

if [ "$DRY_RUN" = true ]; then
    echo -e "${YELLOW}*** DRY RUN MODE - No changes will be made ***${NC}"
    echo ""
fi

# Check prerequisites
if ! check_prerequisites; then
    exit 1
fi

# List and select backup
display_and_select_backup "$SOURCE_NAMESPACE"

# Get backup destination for display
BACKUP_DESTINATION=$(kctl get perconaxtradbclusterbackup "$BACKUP_NAME" -n "$SOURCE_NAMESPACE" -o jsonpath='{.status.destination}' 2>/dev/null || echo "")

# Show summary
log_header "Restore Summary"
echo ""
echo -e "  ${CYAN}Source Namespace:${NC}  ${SOURCE_NAMESPACE}"
echo -e "  ${CYAN}Backup:${NC}            ${BACKUP_NAME}"
echo -e "  ${CYAN}Backup Storage:${NC}    ${BACKUP_STORAGE}"
if [ -n "$BACKUP_DESTINATION" ]; then
    echo -e "  ${CYAN}Backup Location:${NC}   ${BACKUP_DESTINATION}"
fi
if [ "$PITR_AVAILABLE" = true ]; then
    echo -e "  ${CYAN}Restore To:${NC}        ${RESTORE_TIME} UTC"
else
    echo -e "  ${CYAN}Restore To:${NC}        Backup state (non-PITR)"
fi
echo -e "  ${CYAN}Target Cluster:${NC}    ${TARGET_CLUSTER}"
echo -e "  ${CYAN}Target Namespace:${NC}  ${TARGET_NAMESPACE}"
echo ""

if [ "$DRY_RUN" = true ]; then
    log_header "Dry Run - Detailed Validation"
    
    dry_errors=0
    
    # Verify backup exists and is accessible
    echo "Validating backup:"
    backup_state=$(kctl get perconaxtradbclusterbackup "$BACKUP_NAME" -n "$SOURCE_NAMESPACE" -o jsonpath='{.status.state}' 2>/dev/null || echo "")
    backup_destination=$(kctl get perconaxtradbclusterbackup "$BACKUP_NAME" -n "$SOURCE_NAMESPACE" -o jsonpath='{.status.destination}' 2>/dev/null || echo "")
    
    if [ "$backup_state" = "Succeeded" ] || [ "$backup_state" = "Ready" ]; then
        log_dry "  Backup '$BACKUP_NAME' is in $backup_state state"
        if [ -n "$backup_destination" ]; then
            log_dry "  Backup location: $backup_destination"
        fi
    else
        log_error "  Backup '$BACKUP_NAME' is not in Succeeded state (current: ${backup_state:-unknown})"
        ((dry_errors++))
    fi
    echo ""
    
    # Validate target cluster
    echo "Validating target cluster:"
    target_state=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o jsonpath='{.status.state}' 2>/dev/null || echo "")
    if [ "$target_state" = "ready" ]; then
        log_dry "  Target cluster '$TARGET_CLUSTER' is healthy (state: ready)"
    else
        log_error "  Target cluster '$TARGET_CLUSTER' is not healthy (state: ${target_state:-unknown})"
        ((dry_errors++))
    fi
    
    # Show target cluster info
    pxc_ready=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o jsonpath='{.status.pxc.ready}' 2>/dev/null || echo "0")
    pxc_size=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o jsonpath='{.status.pxc.size}' 2>/dev/null || echo "?")
    log_dry "  PXC nodes: $pxc_ready/$pxc_size ready"
    echo ""
    
    # Verify S3/MinIO connectivity and backup accessibility
    echo "Validating S3/MinIO storage access:"
    
    # Get storage configuration from target cluster
    storage_config=$(kctl get perconaxtradbcluster "$TARGET_CLUSTER" -n "$TARGET_NAMESPACE" -o json 2>/dev/null | jq -r ".spec.backup.storages[\"$BACKUP_STORAGE\"].s3 // empty")
    
    if [ -z "$storage_config" ] || [ "$storage_config" = "null" ]; then
        log_error "  Storage '$BACKUP_STORAGE' not found in target cluster config"
        log_error "  The target cluster must have a backup storage named '$BACKUP_STORAGE' configured"
        log_error "  Check: kubectl get pxc $TARGET_CLUSTER -n $TARGET_NAMESPACE -o jsonpath='{.spec.backup.storages}'"
        ((dry_errors++))
    else
        s3_bucket=$(echo "$storage_config" | jq -r '.bucket // empty')
        s3_endpoint=$(echo "$storage_config" | jq -r '.endpointUrl // empty')
        s3_region=$(echo "$storage_config" | jq -r '.region // "us-east-1"')
        s3_creds_secret=$(echo "$storage_config" | jq -r '.credentialsSecret // empty')
        
        # Critical check: bucket must be configured
        if [ -z "$s3_bucket" ]; then
            log_error "  Storage '$BACKUP_STORAGE' exists but has no bucket configured"
            log_error "  This will cause restore to fail with: 'no bucket in storage'"
            log_error "  Fix the target cluster's backup storage configuration"
            ((dry_errors++))
        else
            log_dry "  S3 bucket: $s3_bucket"
        fi
        
        log_dry "  S3 endpoint: ${s3_endpoint:-AWS S3}"
        log_dry "  S3 region: $s3_region"
        
        if [ -z "$s3_creds_secret" ]; then
            log_error "  No credentials secret configured for storage '$BACKUP_STORAGE'"
            ((dry_errors++))
        else
            log_dry "  Credentials secret: $s3_creds_secret"
        fi
        
        if [ -n "$s3_creds_secret" ] && [ -n "$s3_bucket" ]; then
            # Get credentials from secret
            aws_access_key=$(kctl get secret "$s3_creds_secret" -n "$TARGET_NAMESPACE" -o jsonpath='{.data.AWS_ACCESS_KEY_ID}' 2>/dev/null | base64 -d 2>/dev/null || echo "")
            aws_secret_key=$(kctl get secret "$s3_creds_secret" -n "$TARGET_NAMESPACE" -o jsonpath='{.data.AWS_SECRET_ACCESS_KEY}' 2>/dev/null | base64 -d 2>/dev/null || echo "")
            
            if [ -z "$aws_access_key" ] || [ -z "$aws_secret_key" ]; then
                log_error "  Could not retrieve S3 credentials from secret: $s3_creds_secret"
                ((dry_errors++))
            else
                log_dry "  Credentials retrieved successfully"
                
                # Test MinIO connectivity by exec'ing into a MinIO pod
                echo ""
                echo "  Testing MinIO connectivity..."
                
                # Find MinIO pod - try common namespaces and labels
                local minio_pod=""
                local minio_ns=""
                for ns in "minio" "minio-operator" "default" "$TARGET_NAMESPACE" "$SOURCE_NAMESPACE"; do
                    if [ -n "$ns" ] && kctl get namespace "$ns" &>/dev/null; then
                        # Try different label selectors
                        minio_pod=$(kctl get pods -n "$ns" -l "app=minio" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
                        if [ -z "$minio_pod" ]; then
                            minio_pod=$(kctl get pods -n "$ns" -l "app.kubernetes.io/name=minio" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
                        fi
                        if [ -z "$minio_pod" ]; then
                            # Fallback: find any pod with minio in the name
                            minio_pod=$(kctl get pods -n "$ns" --no-headers 2>/dev/null | grep -i "^minio" | grep "Running" | head -1 | awk '{print $1}' || echo "")
                        fi
                        if [ -n "$minio_pod" ]; then
                            minio_ns="$ns"
                            break
                        fi
                    fi
                done
                
                if [ -n "$minio_pod" ] && [ -n "$minio_ns" ]; then
                    log_dry "  Found MinIO pod: $minio_pod in namespace $minio_ns"
                    
                    # Configure mc alias and test bucket access
                    # Use the endpoint from storage config, or construct from service
                    local mc_endpoint="$s3_endpoint"
                    if [ -z "$mc_endpoint" ]; then
                        mc_endpoint="http://minio.${minio_ns}.svc:9000"
                    fi
                    
                    # Test bucket listing using mc
                    local mc_test
                    mc_test=$(kctl exec -n "$minio_ns" "$minio_pod" -- mc alias set testbackup "$mc_endpoint" "$aws_access_key" "$aws_secret_key" 2>&1) || true
                    
                    if kctl exec -n "$minio_ns" "$minio_pod" -- mc ls "testbackup/$s3_bucket" &>/dev/null; then
                        log_success "  Successfully connected to MinIO bucket: $s3_bucket"
                        
                        # Check if backup path exists
                        if [ -n "$backup_destination" ]; then
                            # Extract path from destination (remove s3://bucket/ prefix)
                            backup_path=$(echo "$backup_destination" | sed "s|s3://$s3_bucket/||" | sed 's|s3://[^/]*/||')
                            
                            if [ -n "$backup_path" ]; then
                                echo ""
                                echo "  Checking backup path: $backup_path"
                                
                                local backup_list
                                backup_list=$(kctl exec -n "$minio_ns" "$minio_pod" -- mc ls "testbackup/$s3_bucket/$backup_path" 2>/dev/null | head -5)
                                if [ -n "$backup_list" ]; then
                                    echo "$backup_list" | sed 's/^/    /'
                                    log_success "  Backup data found at: $s3_bucket/$backup_path"
                                else
                                    log_warn "  Could not list backup path (may still work)"
                                fi
                            fi
                        fi
                        
                        # Clean up the alias
                        kctl exec -n "$minio_ns" "$minio_pod" -- mc alias rm testbackup &>/dev/null || true
                    else
                        log_error "  Failed to connect to MinIO bucket: $s3_bucket"
                        log_error "  Endpoint: $mc_endpoint"
                        ((dry_errors++))
                        # Clean up the alias
                        kctl exec -n "$minio_ns" "$minio_pod" -- mc alias rm testbackup &>/dev/null || true
                    fi
                else
                    log_warn "  Could not find MinIO pod - skipping bucket connectivity test"
                    log_info "  Bucket and credentials configuration looks correct"
                fi
            fi
        fi
    fi
    echo ""
    
    # Show restore configuration
    echo "Restore configuration:"
    log_dry "  Backup: $BACKUP_NAME"
    if [ "$PITR_AVAILABLE" = true ]; then
        log_dry "  Restore time: $RESTORE_TIME UTC"
    else
        log_dry "  Restore type: Non-PITR (backup state only)"
    fi
    log_dry "  Storage: $BACKUP_STORAGE"
    log_dry "  Source bucket: $backup_destination"
    echo ""
    
    log_header "Dry Run - Actions Summary"
    echo ""
    log_dry "Source: $SOURCE_NAMESPACE (backups)"
    log_dry "Target: $TARGET_CLUSTER in $TARGET_NAMESPACE (healthy cluster)"
    echo ""
    log_dry "1. Copy backup resource $BACKUP_NAME to $TARGET_NAMESPACE"
    log_dry "2. Create PerconaXtraDBClusterRestore resource"
    log_dry "   - Restore from backup: $BACKUP_NAME"
    if [ "$PITR_AVAILABLE" = true ]; then
        log_dry "   - Point-in-time: $RESTORE_TIME UTC"
    else
        log_dry "   - Non-PITR restore (backup only)"
    fi
    log_dry "3. Wait for restore completion"
    log_dry "4. Display database summary"
    echo ""
    
    if [ $dry_errors -gt 0 ]; then
        log_error "Dry run validation failed with $dry_errors error(s)"
        log_error "Fix the issues above before running without --dry-run"
        exit 1
    fi
    
    log_success "Dry run validation complete. All checks passed."
    log_info "Remove --dry-run to perform the actual restore."
    exit 0
fi

echo -e "${YELLOW}WARNING: This will restore data to the existing cluster in the target namespace.${NC}"
echo -e "${YELLOW}         The source namespace will NOT be modified.${NC}"
echo -e "${YELLOW}         Target cluster: ${TARGET_CLUSTER} in namespace ${TARGET_NAMESPACE}${NC}"
echo ""
echo -n "Proceed with restore? [y/N]: "
read -r confirm

if [[ ! "$confirm" =~ ^[Yy]$ ]]; then
    log_info "Restore cancelled"
    exit 0
fi

# Execute restore to existing target cluster
log_header "Creating Restore Resource"
log_info "Target cluster: $TARGET_CLUSTER (namespace: $TARGET_NAMESPACE)"
log_info "Restoring from backup: $BACKUP_NAME"
if [ "$PITR_AVAILABLE" = true ]; then
    log_info "Point-in-time: $RESTORE_TIME UTC"
else
    log_info "Non-PITR restore (backup only)"
fi
echo ""

create_restore "$TARGET_NAMESPACE" "$TARGET_CLUSTER" "$BACKUP_NAME" "$RESTORE_TIME" "$BACKUP_STORAGE" "$SOURCE_NAMESPACE"
if [ $? -ne 0 ]; then
    log_error "Failed to create restore resource. Aborting."
    exit 1
fi

wait_for_restore "$TARGET_NAMESPACE" "$RESTORE_NAME" "$TARGET_CLUSTER" || exit 1

get_database_summary "$TARGET_NAMESPACE" "$TARGET_CLUSTER"

echo ""
log_success "Restore completed successfully!"
